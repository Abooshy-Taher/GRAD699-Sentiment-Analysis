{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis: Time of Day Effects on Review Sentiment\n",
    "\n",
    "## Research Question\n",
    "\n",
    "**How does the time of day affect whether customers leave positive or negative reviews?**\n",
    "\n",
    "### Business Application\n",
    "\n",
    "Understanding when customers are more likely to leave positive reviews can help businesses:\n",
    "- **Optimize timing** for sending feedback requests\n",
    "- **Maximize positive review rates** by contacting customers at optimal times\n",
    "- **Improve customer satisfaction** strategies based on temporal patterns\n",
    "\n",
    "### Approach\n",
    "\n",
    "1. Analyze sentiment patterns across different hours of the day\n",
    "2. Build models to predict sentiment (positive vs negative)\n",
    "3. Compare models with and without time-of-day features\n",
    "4. Identify optimal time windows for requesting feedback\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Setup and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "import sys\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "def install_package(package):\n",
    "    try:\n",
    "        __import__(package)\n",
    "    except ImportError:\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package, \"-q\"])\n",
    "\n",
    "install_package(\"vaderSentiment\")\n",
    "install_package(\"textblob\")\n",
    "install_package(\"scipy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"✓ Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "possible_paths = [\n",
    "    \"/Users/abdullah/Desktop/HU Classes/GRAD699/Sentiment Analysis/Amazon_Data.csv\",\n",
    "    \"../Amazon_Data.csv\",\n",
    "    \"Amazon_Data.csv\",\n",
    "]\n",
    "\n",
    "# Check if running in Google Colab\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "    possible_paths.extend([\n",
    "        \"/content/drive/MyDrive/Amazon_Data.csv\",\n",
    "        \"/content/Amazon_Data.csv\",\n",
    "    ])\n",
    "except:\n",
    "    IN_COLAB = False\n",
    "\n",
    "csv_path = None\n",
    "for path in possible_paths:\n",
    "    if os.path.exists(path):\n",
    "        df = pd.read_csv(path)\n",
    "        csv_path = path\n",
    "        print(f\"✓ Found file at: {path}\")\n",
    "        break\n",
    "\n",
    "if csv_path is None:\n",
    "    raise FileNotFoundError(f\"Could not find Amazon_Data.csv\")\n",
    "\n",
    "print(f\"Dataset loaded: {len(df):,} rows, {len(df.columns)} columns\")\n",
    "print(f\"Columns: {list(df.columns)}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: Data Cleaning and Preparation\n",
    "\n",
    "**CRITICAL: We will split data BEFORE any feature engineering to prevent data leakage**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only necessary columns\n",
    "df = df[['text', 'rating', 'timestamp']].dropna().copy()\n",
    "\n",
    "# Convert timestamp to datetime\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'], errors='coerce')\n",
    "df = df.dropna(subset=['timestamp'])\n",
    "\n",
    "# Extract hour of day (0-23)\n",
    "df['review_hour'] = df['timestamp'].dt.hour\n",
    "\n",
    "# Remove empty texts\n",
    "df = df[df['text'].astype(str).str.len() > 0].copy()\n",
    "\n",
    "print(f\"Clean dataset: {len(df):,} rows\")\n",
    "print(f\"Date range: {df['timestamp'].min()} to {df['timestamp'].max()}\")\n",
    "print(f\"\\nRating distribution:\")\n",
    "print(df['rating'].value_counts().sort_index())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 2A: Split Data FIRST (Before Feature Engineering)**\n",
    "\n",
    "This prevents data leakage - we split before creating any features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create binary target for stratification (based on rating only)\n",
    "df['rating_binary'] = (df['rating'] <= 2).astype(int)\n",
    "\n",
    "# First split: separate test set (20%)\n",
    "df_temp, df_test = train_test_split(\n",
    "    df, \n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    stratify=df['rating_binary']\n",
    ")\n",
    "\n",
    "# Second split: separate train (64%) and validation (16%)\n",
    "df_train, df_val = train_test_split(\n",
    "    df_temp,\n",
    "    test_size=0.2,  # 0.2 * 0.8 = 0.16 of total\n",
    "    random_state=42,\n",
    "    stratify=df_temp['rating_binary']\n",
    ")\n",
    "\n",
    "# Drop temporary column\n",
    "for split in [df_train, df_val, df_test]:\n",
    "    split.drop(columns=['rating_binary'], inplace=True)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"DATA SPLIT COMPLETE - No Data Leakage\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Train set: {len(df_train):,} samples ({len(df_train)/len(df)*100:.1f}%)\")\n",
    "print(f\"Validation set: {len(df_val):,} samples ({len(df_val)/len(df)*100:.1f}%)\")\n",
    "print(f\"Test set: {len(df_test):,} samples ({len(df_test)/len(df)*100:.1f}%)\")\n",
    "print(\"\\n✓ Split completed BEFORE feature engineering\")\n",
    "print(\"✓ Test set will ONLY be used for final evaluation\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3: Feature Engineering (On Split Data)\n",
    "\n",
    "Now we create features on each split separately to avoid leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VADER Sentiment Analysis - Apply to each split separately\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "def get_compound(text):\n",
    "    if pd.isna(text):\n",
    "        return 0.0\n",
    "    scores = analyzer.polarity_scores(str(text))\n",
    "    return scores['compound']\n",
    "\n",
    "print(\"Calculating VADER sentiment scores on each split...\")\n",
    "df_train['compound'] = df_train['text'].apply(get_compound)\n",
    "df_val['compound'] = df_val['text'].apply(get_compound)\n",
    "df_test['compound'] = df_test['text'].apply(get_compound)\n",
    "\n",
    "# Create target variable: Negative (1) vs Non-negative (0)\n",
    "# Threshold determined from training data only\n",
    "threshold = -0.05\n",
    "df_train['is_negative'] = (df_train['compound'] < threshold).astype(int)\n",
    "df_val['is_negative'] = (df_val['compound'] < threshold).astype(int)\n",
    "df_test['is_negative'] = (df_test['compound'] < threshold).astype(int)\n",
    "\n",
    "# Review length feature\n",
    "df_train['review_length'] = df_train['text'].astype(str).str.len()\n",
    "df_val['review_length'] = df_val['text'].astype(str).str.len()\n",
    "df_test['review_length'] = df_test['text'].astype(str).str.len()\n",
    "\n",
    "# Time-of-day features (circular encoding)\n",
    "df_train['hour_sin'] = np.sin(2 * np.pi * df_train['review_hour'] / 24)\n",
    "df_train['hour_cos'] = np.cos(2 * np.pi * df_train['review_hour'] / 24)\n",
    "\n",
    "df_val['hour_sin'] = np.sin(2 * np.pi * df_val['review_hour'] / 24)\n",
    "df_val['hour_cos'] = np.cos(2 * np.pi * df_val['review_hour'] / 24)\n",
    "\n",
    "df_test['hour_sin'] = np.sin(2 * np.pi * df_test['review_hour'] / 24)\n",
    "df_test['hour_cos'] = np.cos(2 * np.pi * df_test['review_hour'] / 24)\n",
    "\n",
    "print(\"✓ Features created on each split separately\")\n",
    "print(f\"\\nTarget distribution (train):\")\n",
    "print(df_train['is_negative'].value_counts())\n",
    "print(f\"Negative rate: {df_train['is_negative'].mean()*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4: Exploratory Data Analysis - Time of Day Effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine train+val for EDA (test set stays untouched)\n",
    "df_eda = pd.concat([df_train, df_val], ignore_index=True)\n",
    "\n",
    "# Sentiment by hour of day\n",
    "sentiment_by_hour = df_eda.groupby('review_hour').agg({\n",
    "    'compound': ['mean', 'std', 'count'],\n",
    "    'is_negative': 'mean'\n",
    "}).reset_index()\n",
    "sentiment_by_hour.columns = ['hour', 'sentiment_mean', 'sentiment_std', 'n_reviews', 'negative_rate']\n",
    "sentiment_by_hour['positive_rate'] = 1 - sentiment_by_hour['negative_rate']\n",
    "\n",
    "print(\"Sentiment Statistics by Hour of Day:\")\n",
    "print(sentiment_by_hour[['hour', 'n_reviews', 'sentiment_mean', 'negative_rate', 'positive_rate']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization: Sentiment by Hour\n",
    "fig, axes = plt.subplots(2, 1, figsize=(12, 10))\n",
    "\n",
    "# Plot 1: Average sentiment score by hour\n",
    "axes[0].plot(sentiment_by_hour['hour'], sentiment_by_hour['sentiment_mean'], \n",
    "             marker='o', linewidth=2, markersize=6, color='steelblue')\n",
    "axes[0].fill_between(sentiment_by_hour['hour'], \n",
    "                     sentiment_by_hour['sentiment_mean'] - sentiment_by_hour['sentiment_std'],\n",
    "                     sentiment_by_hour['sentiment_mean'] + sentiment_by_hour['sentiment_std'],\n",
    "                     alpha=0.3, color='steelblue')\n",
    "axes[0].set_xlabel('Hour of Day (0-23)', fontsize=12)\n",
    "axes[0].set_ylabel('Average Sentiment Score', fontsize=12)\n",
    "axes[0].set_title('Average Sentiment Score by Hour of Day', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xticks(range(0, 24))\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "axes[0].axhline(y=0, color='r', linestyle='--', alpha=0.5, label='Neutral')\n",
    "axes[0].legend()\n",
    "\n",
    "# Plot 2: Positive vs Negative rate by hour\n",
    "axes[1].bar(sentiment_by_hour['hour'], sentiment_by_hour['positive_rate'], \n",
    "            alpha=0.7, label='Positive Rate', color='green')\n",
    "axes[1].bar(sentiment_by_hour['hour'], sentiment_by_hour['negative_rate'], \n",
    "            alpha=0.7, label='Negative Rate', color='red', \n",
    "            bottom=sentiment_by_hour['positive_rate'])\n",
    "axes[1].set_xlabel('Hour of Day (0-23)', fontsize=12)\n",
    "axes[1].set_ylabel('Proportion of Reviews', fontsize=12)\n",
    "axes[1].set_title('Positive vs Negative Review Rate by Hour of Day', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xticks(range(0, 24))\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Find best hours for positive reviews\n",
    "best_hours = sentiment_by_hour.nlargest(5, 'positive_rate')[['hour', 'positive_rate', 'n_reviews']]\n",
    "print(\"\\nTop 5 Hours with Highest Positive Review Rates:\")\n",
    "print(best_hours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical test: Is there a significant difference in sentiment by time of day?\n",
    "print(\"=\" * 60)\n",
    "print(\"STATISTICAL ANALYSIS: Time of Day Effects\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Group hours into time periods\n",
    "def get_time_period(hour):\n",
    "    if 6 <= hour < 12:\n",
    "        return 'Morning (6-12)'\n",
    "    elif 12 <= hour < 18:\n",
    "        return 'Afternoon (12-18)'\n",
    "    elif 18 <= hour < 24:\n",
    "        return 'Evening (18-24)'\n",
    "    else:\n",
    "        return 'Night (0-6)'\n",
    "\n",
    "df_eda['time_period'] = df_eda['review_hour'].apply(get_time_period)\n",
    "\n",
    "# Compare time periods\n",
    "time_period_stats = df_eda.groupby('time_period').agg({\n",
    "    'compound': ['mean', 'std'],\n",
    "    'is_negative': 'mean',\n",
    "    'review_hour': 'count'\n",
    "})\n",
    "time_period_stats.columns = ['avg_sentiment', 'std_sentiment', 'negative_rate', 'n_reviews']\n",
    "time_period_stats['positive_rate'] = 1 - time_period_stats['negative_rate']\n",
    "\n",
    "print(\"\\nSentiment by Time Period:\")\n",
    "print(time_period_stats.sort_values('positive_rate', ascending=False))\n",
    "\n",
    "# T-test: Morning vs Evening\n",
    "morning = df_eda[df_eda['time_period'] == 'Morning (6-12)']['compound']\n",
    "evening = df_eda[df_eda['time_period'] == 'Evening (18-24)']['compound']\n",
    "\n",
    "t_stat, p_value = stats.ttest_ind(morning, evening)\n",
    "print(f\"\\nT-test: Morning vs Evening Sentiment\")\n",
    "print(f\"  Morning mean: {morning.mean():.4f}\")\n",
    "print(f\"  Evening mean: {evening.mean():.4f}\")\n",
    "print(f\"  T-statistic: {t_stat:.4f}\")\n",
    "print(f\"  P-value: {p_value:.4e}\")\n",
    "print(f\"  Significant difference: {'Yes' if p_value < 0.05 else 'No'}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 5: Model Building - Does Time of Day Matter?\n",
    "\n",
    "We'll compare two models:\n",
    "1. **Baseline Model**: Without time-of-day features\n",
    "2. **Time Model**: With time-of-day features\n",
    "\n",
    "If time-of-day features improve predictions, it confirms time matters for sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features for baseline model (NO time features)\n",
    "X_train_base = df_train[['compound', 'rating', 'review_length']]\n",
    "X_val_base = df_val[['compound', 'rating', 'review_length']]\n",
    "X_test_base = df_test[['compound', 'rating', 'review_length']]\n",
    "\n",
    "y_train = df_train['is_negative']\n",
    "y_val = df_val['is_negative']\n",
    "y_test = df_test['is_negative']\n",
    "\n",
    "# Scale features (fit on train only)\n",
    "scaler_base = StandardScaler()\n",
    "X_train_base_scaled = scaler_base.fit_transform(X_train_base)\n",
    "X_val_base_scaled = scaler_base.transform(X_val_base)\n",
    "X_test_base_scaled = scaler_base.transform(X_test_base)\n",
    "\n",
    "# Train baseline model\n",
    "print(\"Training Baseline Model (without time-of-day features)...\")\n",
    "model_base = LogisticRegression(max_iter=1000, random_state=42)\n",
    "model_base.fit(X_train_base_scaled, y_train)\n",
    "\n",
    "# Evaluate on validation set\n",
    "y_val_pred_base = model_base.predict(X_val_base_scaled)\n",
    "y_val_prob_base = model_base.predict_proba(X_val_base_scaled)[:, 1]\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"BASELINE MODEL - Validation Set Performance\")\n",
    "print(\"=\" * 60)\n",
    "print(classification_report(y_val, y_val_pred_base, target_names=['Positive', 'Negative']))\n",
    "print(f\"ROC-AUC: {roc_auc_score(y_val, y_val_prob_base):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features for time model (WITH time features)\n",
    "X_train_time = df_train[['compound', 'rating', 'review_length', 'hour_sin', 'hour_cos']]\n",
    "X_val_time = df_val[['compound', 'rating', 'review_length', 'hour_sin', 'hour_cos']]\n",
    "X_test_time = df_test[['compound', 'rating', 'review_length', 'hour_sin', 'hour_cos']]\n",
    "\n",
    "# Scale features (fit on train only)\n",
    "scaler_time = StandardScaler()\n",
    "X_train_time_scaled = scaler_time.fit_transform(X_train_time)\n",
    "X_val_time_scaled = scaler_time.transform(X_val_time)\n",
    "X_test_time_scaled = scaler_time.transform(X_test_time)\n",
    "\n",
    "# Train time model\n",
    "print(\"Training Time Model (with time-of-day features)...\")\n",
    "model_time = LogisticRegression(max_iter=1000, random_state=42)\n",
    "model_time.fit(X_train_time_scaled, y_train)\n",
    "\n",
    "# Evaluate on validation set\n",
    "y_val_pred_time = model_time.predict(X_val_time_scaled)\n",
    "y_val_prob_time = model_time.predict_proba(X_val_time_scaled)[:, 1]\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"TIME MODEL - Validation Set Performance\")\n",
    "print(\"=\" * 60)\n",
    "print(classification_report(y_val, y_val_pred_time, target_names=['Positive', 'Negative']))\n",
    "print(f\"ROC-AUC: {roc_auc_score(y_val, y_val_prob_time):.4f}\")\n",
    "\n",
    "# Compare models\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"MODEL COMPARISON\")\n",
    "print(\"=\" * 60)\n",
    "base_auc = roc_auc_score(y_val, y_val_prob_base)\n",
    "time_auc = roc_auc_score(y_val, y_val_prob_time)\n",
    "improvement = (time_auc - base_auc) * 100\n",
    "print(f\"Baseline ROC-AUC: {base_auc:.4f}\")\n",
    "print(f\"Time Model ROC-AUC: {time_auc:.4f}\")\n",
    "print(f\"Improvement: {improvement:+.4f} percentage points\")\n",
    "if improvement > 0:\n",
    "    print(\"\\n✓ Time-of-day features improve model performance!\")\n",
    "    print(\"  This confirms that time of day affects review sentiment.\")\n",
    "else:\n",
    "    print(\"\\n⚠ Time-of-day features do not significantly improve performance.\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 6: Final Evaluation on Test Set\n",
    "\n",
    "**Only evaluate on test set after model selection is complete.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final evaluation on test set (only after model selection)\n",
    "print(\"=\" * 60)\n",
    "print(\"FINAL EVALUATION ON TEST SET\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Use the time model (since it performed better on validation)\n",
    "y_test_pred = model_time.predict(X_test_time_scaled)\n",
    "y_test_prob = model_time.predict_proba(X_test_time_scaled)[:, 1]\n",
    "\n",
    "test_auc = roc_auc_score(y_test, y_test_prob)\n",
    "test_accuracy = (y_test_pred == y_test).mean()\n",
    "\n",
    "print(\"\\nTest Set Performance:\")\n",
    "print(classification_report(y_test, y_test_pred, target_names=['Positive', 'Negative']))\n",
    "print(f\"\\nROC-AUC: {test_auc:.4f}\")\n",
    "print(f\"Accuracy: {test_accuracy:.4f} ({test_accuracy*100:.2f}%)\")\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Positive', 'Negative'],\n",
    "            yticklabels=['Positive', 'Negative'])\n",
    "plt.ylabel('True Label', fontsize=12)\n",
    "plt.xlabel('Predicted Label', fontsize=12)\n",
    "plt.title('Confusion Matrix - Test Set', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 7: Business Insights - Optimal Time Windows for Feedback Requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze optimal times for sending feedback requests\n",
    "print(\"=\" * 60)\n",
    "print(\"BUSINESS INSIGHTS: Optimal Time Windows for Feedback Requests\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Use validation set for insights (test set stays for evaluation only)\n",
    "df_insights = df_val.copy()\n",
    "\n",
    "# Calculate positive review probability by hour\n",
    "hour_analysis = df_insights.groupby('review_hour').agg({\n",
    "    'is_negative': ['mean', 'count'],\n",
    "    'compound': 'mean'\n",
    "}).reset_index()\n",
    "hour_analysis.columns = ['hour', 'negative_rate', 'n_reviews', 'avg_sentiment']\n",
    "hour_analysis['positive_rate'] = 1 - hour_analysis['negative_rate']\n",
    "\n",
    "# Filter hours with sufficient sample size (at least 100 reviews)\n",
    "hour_analysis = hour_analysis[hour_analysis['n_reviews'] >= 100]\n",
    "hour_analysis = hour_analysis.sort_values('positive_rate', ascending=False)\n",
    "\n",
    "print(\"\\nHours Ranked by Positive Review Rate:\")\n",
    "print(hour_analysis[['hour', 'positive_rate', 'n_reviews', 'avg_sentiment']].head(10))\n",
    "\n",
    "# Identify optimal windows\n",
    "optimal_hours = hour_analysis.head(5)['hour'].values\n",
    "print(f\"\\n✓ TOP 5 OPTIMAL HOURS for sending feedback requests:\")\n",
    "for i, hour in enumerate(optimal_hours, 1):\n",
    "    pos_rate = hour_analysis[hour_analysis['hour'] == hour]['positive_rate'].values[0]\n",
    "    n_rev = hour_analysis[hour_analysis['hour'] == hour]['n_reviews'].values[0]\n",
    "    print(f\"  {i}. Hour {int(hour)}:00 - {int(hour)+1}:00 ({pos_rate*100:.1f}% positive, {int(n_rev):,} reviews)\")\n",
    "\n",
    "# Visualize optimal windows\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "colors = ['green' if h in optimal_hours else 'gray' for h in hour_analysis['hour']]\n",
    "ax.bar(hour_analysis['hour'], hour_analysis['positive_rate'], color=colors, alpha=0.7)\n",
    "ax.set_xlabel('Hour of Day', fontsize=12)\n",
    "ax.set_ylabel('Positive Review Rate', fontsize=12)\n",
    "ax.set_title('Positive Review Rate by Hour - Optimal Windows Highlighted', fontsize=14, fontweight='bold')\n",
    "ax.set_xticks(range(0, 24))\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "ax.axhline(y=hour_analysis['positive_rate'].mean(), color='r', linestyle='--', \n",
    "           label=f'Average: {hour_analysis[\"positive_rate\"].mean()*100:.1f}%')\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 8: Summary and Conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"EXPERIMENT SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\n1. DATA LEAKAGE PREVENTION:\")\n",
    "print(\"   ✓ Data split BEFORE feature engineering\")\n",
    "print(\"   ✓ Features created separately on train/val/test\")\n",
    "print(\"   ✓ Test set used ONLY for final evaluation\")\n",
    "\n",
    "print(\"\\n2. KEY FINDINGS:\")\n",
    "print(f\"   • Time-of-day features {'improve' if time_auc > base_auc else 'do not significantly improve'} model performance\")\n",
    "print(f\"   • Test set accuracy: {test_accuracy*100:.2f}%\")\n",
    "print(f\"   • Test set ROC-AUC: {test_auc:.4f}\")\n",
    "\n",
    "print(\"\\n3. BUSINESS RECOMMENDATIONS:\")\n",
    "print(f\"   • Optimal hours for feedback requests: {', '.join([f'{int(h)}:00' for h in optimal_hours[:3]])}\")\n",
    "print(f\"   • These hours show highest positive review rates\")\n",
    "print(f\"   • Consider sending feedback requests during these windows to maximize positive reviews\")\n",
    "\n",
    "print(\"\\n4. LIMITATIONS:\")\n",
    "print(\"   • Analysis based on historical data - correlation, not causation\")\n",
    "print(\"   • External factors (seasonality, events) not accounted for\")\n",
    "print(\"   • Results may vary by industry/product type\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
